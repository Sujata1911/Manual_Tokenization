# Manual_Tokenization
This node has:
load data,
split by whitespace,
select words by regex,
split by white spaces(no punctuations) and,
Normalizing Case. 
Download the raw file from http://www.gutenberg.org/cache/epub/5200/pg5200.txt before starting the project
This project is based on the blog https://machinelearningmastery.com/clean-text-machine-learning-python/ by Jason Brownlee
