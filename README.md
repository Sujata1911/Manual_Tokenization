# Manual_Tokenization
This node has:
load data,
split by whitespace,
select words by regex,
split by white spaces(no punctuations) and,
Normalizing Case
